import { ChatEngine } from './utils/ChatEngine';
import { SendMessageBody } from './requests/sendMessage.request';
import { forwardRef, Inject, Injectable } from '@nestjs/common';
import { RedisClient } from 'providers/RedisClient';
import { ChatOpenAI } from '@langchain/openai';
import { BaseChatModel } from '@langchain/core/dist/language_models/chat_models';
import { vars } from '../../config/vars';
import { IResponseWithActions, LangChainChatEngine } from './utils/LangChainChatEngine';
import { FineTunedModels } from './utils/LLMEngine';
import { TelegramAPI } from 'providers/Telegram';
import { MyLogger } from 'config/MyLogger';
import { QdrantProvider } from 'providers/QdrantClient';
import { PERSON_DIALOGS_COLLECTION } from '../../common/const/VECTOR_COLLECTIONS_NAMES';
import { YandexMLProvider } from 'providers/YandexML';
import { InjectModel } from '@nestjs/mongoose';
import { DialogStats, DialogStatsDocument } from 'schemas/dialogStats.scheme';
import mongoose, { Model } from 'mongoose';
import { llmContextToVectorData } from '../dialogsData/utils/llmContextToVectorData';
import { ChatGenerationPromptInputs, MessengerPrompts } from './utils/MessengerPrompt';
import { getObjFromLLM } from './utils/getObjFromLLM';
// eslint-disable-next-line @typescript-eslint/no-require-imports
import TelegramBot = require('node-telegram-bot-api');
import OpenAI from 'openai';
import { probabilityCheck } from './utils/propablityCheck';
import { InjectQueue } from '@nestjs/bullmq';
import { Queue } from 'bullmq';
import { splitTextIntoParts } from './utils/splitTextIntoPairs';
import { getSendDelay } from './utils/getSendDelay';


@Injectable()
export class ChatService {
    constructor(
        @Inject(RedisClient)
        private readonly redisClient: RedisClient,
        @Inject(forwardRef(() => TelegramAPI))
        private readonly telegram: TelegramAPI,
        @Inject(forwardRef(() => MyLogger))
        private readonly logger: MyLogger,
        @Inject(forwardRef(() => QdrantProvider))
        private readonly qdrantProvider: QdrantProvider,
        @Inject(forwardRef(() => YandexMLProvider))
        private readonly yandexML: YandexMLProvider,
        @InjectModel(DialogStats.name)
        private dialogStatsModel: Model<DialogStatsDocument>,
        @InjectQueue('sendMessage') private sendMessageQueue: Queue
    ){}
    
    llm:BaseChatModel;
    chatEngine:ChatEngine;
    
    async sendMessage(body:SendMessageBody):Promise<any> {
        const result = await this.onReceiveMessage({
            text: body.text,
            chatId: body.sessionId,
            userId: vars.meUserId,
        });

        return {
            response: result,
        };
    }

    private async getSimilarMessages(dialogPart:string, personId:string):Promise<string[]> {
        const queryVector = await this.yandexML.embeddings.embedQuery(`–°–æ–±–µ—Å–µ–¥–Ω–∏–∫: ${dialogPart}`);

        const result = await this.qdrantProvider.client.query(PERSON_DIALOGS_COLLECTION({
            personId,
        }), {
            query: queryVector,
            params: {
                hnsw_ef: 128,
                exact: false,
            },
            with_payload: true,
            limit: 15,
        });

        return result.points.map((p) => {
            return (p.payload as { text: string }).text;
        });
    }

    async onBotMessageReceived(message:TelegramBot.Message):Promise<void> {
        if (!message.from?.id || !message.text) {
            return;
        }

        this.logger.log('Received text message from bot:', message);

        const responseText = await this.onReceiveMessage({
            text: message.text,
            chatId: message.chat.id.toString(),
            userId: vars.meUserId,
        });

        const splitStr = splitTextIntoParts(responseText, 100, 40);
        const sendDelay = getSendDelay({
            messages: splitStr,
        });

        const jobPromises = sendDelay.map((d) => this.sendMessageQueue.add('messagechunk', {
            text: d.str,
            chatId: message.chat.id,
        }, {
            delay: d.delayMs,
        }));

        await Promise.all(jobPromises);
    }

    private getInitiateMessage = async ({ rag, currentChatHistory }:{ rag: string[], currentChatHistory: string }):Promise<{
        shouldInitiate: boolean,
        message: string,
    }> => {
        const prompt =  `–ü–µ—Ä–µ–¥ —Ç–æ–±–æ–π –ø—Ä–æ–º–ø—Ç —Å–æ–¥–µ—Ä–∂–∞—à–∏–π –∏—Å—Ç–æ—Ä–∏—é —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞, –¥–≤–∞ –ø—Ä–∏–º–µ—Ä–∞ —Å –ø–æ—Ö–æ–∂–∏–º–∏ —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∏–∞–ª–æ–≥–∞–º–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ –ø—Ä–∏–¥—É–º–∞—Ç—å –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è LLM –∫–æ—Ç–æ—Ä–∞—è –≤–µ–¥–µ—Ç –¥–∏–∞–ª–æ–≥ (–≤ —Ç–µ–∫—É—â–µ–º –¥–∏–∞–ª–æ–≥–µ - –Ø —ç—Ç–æ –æ—Ç–≤–µ—Ç—ã LLM). –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –æ–±—ä–µ–∫—Ç–∞ - { "shouldInitiate": true, "initiateMessage": "" }, shouldInitiate - —ç—Ç–æ –ø–æ–ª–µ –æ—Ç–≤–µ—á–∞—é—â–∏–µ –Ω—É–∂–Ω–æ –ª–∏ LLM –∏–Ω—Ü–∏–∞—Ä–æ–≤–∞—Ç—å –æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –Ω–µ—Ç (–ø—Ä–µ–¥–ª–∞–≥–∞–π –∏–Ω—Ü–∏–∏—Ä–æ–≤–∞—Ç—å –æ–±—â–µ–Ω–∏–µ –∫–æ–≥–¥–∞ –∫–∞–∂–µ—Ç—Å—è —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ –≤ –¥–∏–∞–ª–æ–≥–µ –µ—Å—Ç—å –æ—á–µ–≤–∏–¥–Ω–æ–µ –ø—Ä–æ–¥–ª–∂–µ–Ω–∏–µ –∏–ª–∏ –¥–∏–∞–ª–æ–≥ —Å–æ —Å—Ç—Ä–æ–Ω—ã LLM –∫–∞–∂–µ—Ç—Å—è —Å–ª–∏—à–∫–æ–º –Ω–µ–∏—Ü–∏–∞—Ç–∏–≤–Ω—ã–π), initiateMessage - –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç LLM, —Å–æ–æ–±—â–µ–Ω–∏–µ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –∫–æ–Ω—Ç–µ–∫c—Ç LLM, –Ω–µ –±—É–¥—å –Ω–∞–≤—è—â–∏–º –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –≤–æ–ø—Ä–æ—Å—ã –ø–æ –º–Ω–æ–≥—É —Ä–∞–∑, –µ—Å–ª–∏ —á–µ–ª–æ–≤–µ–∫ –Ω–∞ –Ω–∏—Ö –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç. –ö—Ä–æ–º–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –µ—â–µ –º–æ–∂–µ—à—å –ø—Ä–∏–¥—É–º–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –ø—Ä–æ—Å—Ç–æ –æ –Ω–æ–≤–æ–π —Ç–µ–º–µ (–±–ª–∏–∑–∫–æ–π –¥–∏–∞–ª–æ–≥—É) 
–ù–∞–ø–∏—à–∏ –≤ —Å—Ç–∏–ª–µ –æ—Ç–≤–µ—Ç–æ–≤ (—Ç–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã —ç—Ç–æ, —Ç–æ —á—Ç–æ –ø–æ—Å–ª–µ –Ø:) –∏–∑ —Å–ª–µ–¥—É—é—â–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤: 
${rag.join('\n')}

### –ü—Ä–æ–º–ø—Ç —Å –∏—Å—Ç–æ—Ä–∏–µ–π –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ —Ç—ã –¥–æ–ª–∂–µ–Ω –ø—Ä–∏–¥—É–º–∞—Ç—å –Ω–æ–≤–æ–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–Ω–æ–µ —Å–æ–æ–±—â–Ω–∏–µ:
–¢—ã ‚Äì –ù–∏–∫–∏—Ç–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äì –æ–±—â–∞—Ç—å—Å—è –≤ —á–∞—Ç–µ —Ç–∞–∫, –∫–∞–∫ –±—É–¥—Ç–æ —ç—Ç–æ –¥–µ–ª–∞–µ—à—å —Ç—ã —Å–∞–º(–∞). –¢–≤–æ–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–ª–∏–∑–æ–∫ –∫ —Ç–æ–º—É, –∫–∞–∫ —Ç—ã –æ–±—ã—á–Ω–æ –æ–±—â–∞–µ—à—å—Å—è –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–∞—Ö.
–ü–æ–º–∏–º–æ —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∑–∞–¥–∞–≤–∞–π –∏ —Å–≤–æ–∏ –≤–º–µ—Å—Ç–µ —Å –æ—Ç–≤–µ—Ç–æ–º –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –Ω–æ —Ç–∞–∫ —á—Ç–æ–±—ã —ç—Ç–æ –±—ã–ª–æ —É–º–µ—Å—Ç–Ω–æ.
–ú–Ω–µ 23 –≥–æ–¥–∞ —è –º—É–∂—á–∏–Ω–∞. –ñ–∏–≤—É –≤ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ, –∑–∞–∫–∞–Ω—á–∏–≤–∞—é –º–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä—É. –õ—é–±–ª—é —à—É—Ç–∏—Ç—å (—á–∞—Å—Ç–æ –∏—Ä–æ–Ω–∏–∑–∏—Ä—É—é). –û—Ç–≤–µ—á–∞—é –∫—Ä–∞—Ç–∫–æ, –Ω–æ –ø–æ –¥–µ–ª—É. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Å—å –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º, AI, –≤–µ–ª–æ—Å–∏–ø–µ–¥–∞–º–∏.

### –ò—Å—Ç–æ—Ä–∏—è —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è):
${currentChatHistory}
--- –ö–û–ù–ï–¶ –ò–°–¢–û–†–ò–ò –¢–ï–ö–£–©–ï–ì–û –î–ò–ê–õ–û–ì–ê ---

### –ü–æ—Ö–æ–∂–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ —Ç–≤–æ–∏—Ö –ø—Ä–æ—à–ª—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö –∫–∞–∫ –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ –¥–ª—è —Å—Ç–∏–ª—è –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è, –º–æ–∂–µ—à—å –±—Ä–∞—Ç—å –æ—Ç—Å—é–¥–∞ –∏–¥–µ—è –¥–ª—è –∏–Ω—Ü–∏–∞—Ç–∏–≤–Ω–æ–≥–æ –æ–±—â–µ–Ω–∏—è –≤ –¥–∏–∞–ª–æ–≥–µ, –Ω–æ –ù–ï –ö–û–ü–ò–†–£–ô –¥–æ—Å–ª–æ–≤–Ω–æ):

–ü—Ä–∏–º–µ—Ä 1:
${rag[0]}
--- –ö–û–ù–ï–¶ –ü–†–ò–ú–ï–†–ê 1 ---

–ü—Ä–∏–º–µ—Ä 2:
${rag[1]}
--- –ö–û–ù–ï–¶ –ü–†–ò–ú–ï–†–ê 2 ---`;

        const client = new OpenAI({
            baseURL: 'https://openrouter.ai/api/v1',
            apiKey: vars.openRouter.key,
        });

        const completion = await client.chat.completions.create({
            model: 'x-ai/grok-3-beta',
            messages: [
                {
                    role: 'user',
                    content: prompt,
                },
            ],
        });

        const result = getObjFromLLM({
            llmResult: completion.choices[0].message.content as string,
        });

        return {
            shouldInitiate: result.obj.shouldInitiate || false,
            message: result.obj.initiateMessage || '',
        };
    };

    private async getPrompt({ 
        rag1,
        rag2,
        isCorrectionNeeded,
        previousGeneratedResponse,
        verifierLlmFeedback,
        currentChatHistory,
    }:{
        rag1: string,
        rag2: string,
        isCorrectionNeeded: boolean,
        previousGeneratedResponse?: string,
        verifierLlmFeedback?: string,
        currentChatHistory: string,
    }) {
        const messengerPrompts = new MessengerPrompts();

        const initialInputs: ChatGenerationPromptInputs = {
            userNameOrNickname: '–ù–∏–∫–∏—Ç–∞',
            userPersonalityDetails: '–ú–Ω–µ 23 –≥–æ–¥–∞ —è –º—É–∂—á–∏–Ω–∞. –ñ–∏–≤—É –≤ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ, –∑–∞–∫–∞–Ω—á–∏–≤–∞—é –º–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä—É. –õ—é–±–ª—é —à—É—Ç–∏—Ç—å (—á–∞—Å—Ç–æ –∏—Ä–æ–Ω–∏–∑–∏—Ä—É—é), —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é —ç–º–æ–¥–∑–∏. –û—Ç–≤–µ—á–∞—é –∫—Ä–∞—Ç–∫–æ, –Ω–æ –ø–æ –¥–µ–ª—É. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Å—å –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º, AI, –≤–µ–ª–æ—Å–∏–ø–µ–¥–∞–º–∏.',
            ragExample1: rag1,
            ragExample2: rag2,
            isCorrectionNeeded: false,
            currentChatHistory,
        };

        if (isCorrectionNeeded) {
            initialInputs.isCorrectionNeeded = true;
            initialInputs.previousGeneratedResponse = previousGeneratedResponse;
            initialInputs.verifierLlmFeedback = verifierLlmFeedback;
        }

        return messengerPrompts.formatChatPrompt(initialInputs);
    };

    private async evaluateLLMAnswer({ currentDialog }:{ currentDialog: string }):Promise<{
        shouldRetry: boolean,
        shouldInitiate: boolean,
        retryDesc: string,
    }> {
        const model = new ChatOpenAI({
            model: 'deepseek-ai/DeepSeek-V3',
            configuration: {
                baseURL: vars.nebius.baseUrl,
                apiKey: vars.nebius.secretKey,
            },
            temperature: 0.1,
        });

        const prompt = '–£ —Ç–µ–±—è –µ—Å—Ç—å —á–∞—Å—Ç—å –ø–µ—Ä–µ–ø–µ—Å–∫–∏, –≥–¥–µ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±—ã–ª–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ LLM,' +
            ' —Ç–µ–±–µ –Ω—É–∂–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. –°–æ–æ–±—â–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è –Ω–µ–ª–æ–≥–∏—á–Ω—ã–º, ' +
            '–µ—Å–ª–∏ –Ω–µ –≤–æ–∑–º–æ–∂–Ω–æ –ø–æ–Ω—è—Ç—å –µ–≥–æ —Å–≤—è–∑—å —Å –æ—Å—Ç–∞–ª—å–Ω–æ–π –ø–µ—Ä–µ–ø–∏—Å–∫–æ–π. –û—Ç–≤–µ—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –æ—Å–∫–æ—Ä–±–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–ª–∏ –∏—Ä–æ–Ω–∏—á–Ω—ã–º–∏.' +
            ' –¢–∞–∫-–∂–µ –æ—Ü–µ–Ω–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –¥–∏–∞–ª–æ–≥ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã LLM —Å–ª–∏—à–∫–æ–º –ø–∞—Å—Å–∏–≤–Ω—ã–º (–Ω–µ –ø–æ—Ö–æ–∂ –ª–∏ –æ–Ω –Ω–∞ –∏–Ω—Ç–µ—Ä–≤—å—é –≥–¥–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å—Ç–æ –∑–∞–¥–∞–µ—Ç –≤–æ–ø—Ä–æ—Å—ã)' +
            ' –û—Ç–≤–µ—á–∞–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –æ–±—ä–µ–∫—Ç–∞:' +
            ' { "shouldRetry": boolean, "shouldInitiate": boolean, "retryDesc": string }. shouldRetry - –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç, shouldInitiate - –Ω—É–∂–Ω–∞ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞ –æ—Ç LLM, retryDesc -' +
            ' –ø–æ–¥—Å–∫–∞–∑–∫–∞ –¥–ª—è LLM –ø–æ—á–µ–º—É –æ—Ç–≤–µ—Ç –Ω–µ –≤–µ—Ä–Ω—ã–π. –í–æ–∑–≤—Ä–∞—â–∞–π —Ç–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç –≤–∏–¥–∞ { "shouldRetry": boolean, "shouldInitiate": boolean, "retryDesc": string }, –û—Ü–µ–Ω–∏–≤–∞–π —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç—ã LLM (—Ç–æ –µ—Å—Ç—å –Ø:), –Ω–µ –æ—Ü–µ–Ω–∏–≤–∞–π –æ—Ç–≤–µ—Ç—ã —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞, (–°–æ–±–µ—Å–µ–¥–Ω–∏–∫:) –¥–∞–∂–µ –ø–æ—Å–ª–µ–¥–Ω–∏–∏' +

            '–ü—Ä–∏–º–µ—Ä 1: \n' +
            '–°–æ–±–µ—Å–µ–¥–Ω–∏–∫: –ù–µ—Ç'+
            '–Ø: —Ç—ã –≥–¥–µ  \n' +
            '–°–æ–±–µ—Å–µ–¥–Ω–∏–∫: –ò–¥—É  \n' +
            '–Ø: –∫—É–¥–∞....  \n' +
            '–°–æ–±–µ—Å–µ–¥–Ω–∏–∫: –î–æ–º–æ–π' +
            '–Ø: –Ω–∏—á–µ–≤–æ –Ω–µ –∑–∞–±—ã–ª ? üò•' +
            '–°–æ–±–µ—Å–µ–¥–Ω–∏–∫: –° –¥–Ω–µ–º —Ä–æ–∂–¥–µ–Ω–∏—è –í—Å–ø–æ–º–Ω–∏–ª... –ù–æ —É –º–µ–Ω—è –±–∞—à–∫–∞ —â–∞ –ª–æ–ø–Ω–µ—Ç... –û—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\\n\' +\n' +
            '–Ø: –õ–∞–¥–Ω–æ –°–∏–¥–∏ –æ—Å–º—ã—Å–ª—è–π –£—Å–ª—ã—à–∞–Ω–Ω–æ–µ  \n' +
            '–û—Ç–≤–µ—Ç 1 { "shouldRetry": false, "shouldInitiate": false, "retryDesc": "" }  \n' +

            '–ü—Ä–∏–º–µ—Ä 2: \n' +
            '–Ø: –ß—Ç–æ –≤ —Å—É–±–±–æ—Ç—É –¥–µ–ª–∞–µ—à—å? \n ' +
            '–°–æ–±–µ—Å–µ–¥–Ω–∏–∫: –í —à–∫–æ–ª—É  \n' +
            '–Ø: –¥–æ —Å–∫–æ–ª—å–∫–∏?  \n' +
            '–°–æ–±–µ—Å–µ–¥–Ω–∏–∫: –î–æ 2.30  \n' +
            '–Ø: –¥–∞–≤–∞–π –≤ —Å–µ—Å—Ç—Ä–æ—Ä–µ—Ü–∫ –ø–æ—Å–ª–µ  \n' +
            '–Ø: –ú–æ–∂–Ω–æ  \n' +
            '–°–æ–±–µ—Å–µ–¥–Ω–∏–∫:–≤—Å–µ, —Ç–æ–≥–¥–∞ –≥–¥–µ –≤—Å—Ç—Ä–µ—á–∞–µ–º—Å—è?  \n' +
            '–Ø: –í —à–∫–æ–ª–µ  \n' +
            '–°–æ–±–µ—Å–µ–¥–Ω–∏–∫:...  \n' +
            '–Ø: —Ç–∞–º –ø–æ–π–¥—ë–º –≤ –∫–∏–Ω–æ  \n' +
            '–û—Ç–≤–µ—Ç 2: { "shouldRetry": true, "shouldInitiate": true, "retryDesc": "–ü–æ–π–¥–µ–º –≤ –∫–∏–Ω–æ –Ω–µ —Å–≤—è–∑–∞–Ω–æ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–∏–∞–ª–æ–≥–∞ (–æ–Ω–æ –ª–æ–º–∞–µ—Ç –µ–≥–æ —Å–º—ã—Å–ª–∞), —à—É—Ç–∫–æ–π –∏–ª–∏ –∏—Ä–æ–Ω–∏–µ–π —ç—Ç–æ –Ω–µ–ª—å–∑—è –Ω–∞–∑–≤–∞—Ç—å" } \n' +
            '–¢–µ–ø–µ—Ä—å –æ—Ü–µ–Ω–∏ —ç—Ç–æ—Ç –¥–∏–∞–ª–æ–≥: \n' + currentDialog;

        const aiMsg = await model.invoke(prompt);
        const result = getObjFromLLM({
            llmResult: aiMsg.content as string,
        });

        if (result.isValid) {
            return {
                shouldRetry: result.obj.shouldRetry || false,
                shouldInitiate: result.obj.shouldInitiate || false,
                retryDesc: result.obj.retryDesc || '',
            };
        }
        return {
            shouldRetry: false,
            shouldInitiate: false,
            retryDesc: '',
        };
    }

    private async tryGetAnswerFromLLM({ chatId, prompt, humanMessage }:{ chatId: string, prompt: string, humanMessage: string }):Promise<IResponseWithActions> {
        this.llm = new ChatOpenAI({
            configuration: {
                baseURL: vars.nebius.baseUrl,
                apiKey: vars.nebius.secretKey,
            },
            model: FineTunedModels.Llama70bAllMy,
            temperature: 0.8,
            topP: 0.6,
        });
        /*
            Good For Bashir:
            temperature: 0.8,
            topP: 0.9,

            Good for MyAll
            temperature: 0.8,
            topP: 0.6,
         */

        const chain = new LangChainChatEngine({
            llm: this.llm,
            sessionId: chatId,
        });

        return await chain.invoke({ prompt, humanMessage });
    }

    private async getAnswerFromLLm({
        retryLimit,
        currentRetry,
        chatId,
        rag,
        isCorrectionNeeded,
        humanMessage,
        previousGeneratedResponse,
        verifierLlmFeedback,
        currentChatHistory,
    }:{
        retryLimit: number,
        currentRetry: number,
        chatId: string,
        rag: string[],
        humanMessage: string,
        currentChatHistory: string,
        isCorrectionNeeded?: boolean,
        previousGeneratedResponse?: string,
        verifierLlmFeedback?: string,
    }):Promise<string> {
        try {
            const prompt = await this.getPrompt({
                rag1: rag[0],
                rag2: rag[1],
                isCorrectionNeeded: isCorrectionNeeded || false,
                previousGeneratedResponse,
                verifierLlmFeedback,
                currentChatHistory,
            });

            const llmAnswer = await this.tryGetAnswerFromLLM({
                chatId,
                prompt,
                humanMessage,
            });

            const resultAnswer = await this.evaluateLLMAnswer({
                currentDialog: currentChatHistory + ` \n –Ø: ${llmAnswer.response}`,
            });

            if (resultAnswer.shouldRetry && (retryLimit > currentRetry)) {
                this.logger.log(`retry ${currentRetry}, answer: ${llmAnswer.response}, feedback ${resultAnswer.retryDesc}`);
                return this.getAnswerFromLLm({
                    retryLimit,
                    currentRetry: currentRetry + 1,
                    chatId,
                    rag,
                    isCorrectionNeeded: true,
                    previousGeneratedResponse: llmAnswer.response,
                    verifierLlmFeedback: resultAnswer.retryDesc,
                    humanMessage,
                    currentChatHistory,
                });
            }

            let saveInitiate = '';

            if (resultAnswer.shouldInitiate && probabilityCheck(0.3)) {
                const result = await this.getInitiateMessage({
                    rag,
                    currentChatHistory: currentChatHistory + ` \n –Ø: ${llmAnswer.response}`,
                });

                if (result.shouldInitiate) {
                    saveInitiate = result.message;
                    llmAnswer.response = llmAnswer.response + ' ' + result.message;
                }
            }

            await llmAnswer.onSaveContext();

            if (saveInitiate) {
                await llmAnswer.onAppendNewMessage(saveInitiate);
            }

            return llmAnswer.response;
        } catch (e) {
            this.logger.error('error get Answer from llm', e);
            if (retryLimit > currentRetry) {
                return this.getAnswerFromLLm({
                    retryLimit,
                    currentRetry: currentRetry + 1,
                    chatId,
                    rag,
                    isCorrectionNeeded,
                    previousGeneratedResponse,
                    verifierLlmFeedback,
                    humanMessage,
                    currentChatHistory,
                });
            }

            return '';
        }
    };

    private async onReceiveMessage({ text, chatId, userId }:{ text: string, chatId: string, userId: string }):Promise<string> {
        const selectedDialogStats = await this.dialogStatsModel.findOne({
            ownerUserId: new mongoose.Types.ObjectId(userId),
            isSelected: true,
        });

        if (!selectedDialogStats) {
            return '';
        }

        const dialogHistory = await this.redisClient.client.lrange(chatId, 0, -1);
        const parsedDialogHistory = dialogHistory.map((d) => JSON.parse(d));
        let lastDialogHistoryInText = llmContextToVectorData(parsedDialogHistory.slice(0, 100).reverse());
        lastDialogHistoryInText = `${lastDialogHistoryInText}\n –°–æ–±–µ—Å–µ–¥–Ω–∏–∫:${text} \n`;

        const similarMessages = await this.getSimilarMessages(lastDialogHistoryInText, selectedDialogStats.personId);

        return this.getAnswerFromLLm({
            retryLimit: 10,
            currentRetry: 1,
            chatId,
            rag: similarMessages,
            isCorrectionNeeded: false,
            humanMessage: text,
            currentChatHistory: lastDialogHistoryInText,
        });
    }
}